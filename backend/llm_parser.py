# backend/llm_parser.py

from dotenv import load_dotenv
load_dotenv()

import os
import json
from openai import OpenAI


# â­ í™˜ê²½ë³€ìˆ˜ì—ì„œ API KEY ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    print("âŒ ERROR: OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    client = None
else:
    client = OpenAI(api_key=api_key)


# ----------------------------------------------------
# RAG ê±°ë¦¬ ê¸°ì¤€
# ----------------------------------------------------
RAG_DISTANCE_HINT = """
[ì‹œì„¤ë³„ ì¼ë°˜ì ì¸ ê±°ë¦¬ ê¸°ì¤€]
- ì§€í•˜ì²  ê°€ê¹Œì›€: 400~600m
- ë²„ìŠ¤ì •ë¥˜ì¥ ê°€ê¹Œì›€: 100~300m
- ì´ˆë“±í•™êµ ê°€ê¹Œì›€: 500~800m
- ì¤‘í•™êµ ê°€ê¹Œì›€: 500~900m
- ë³‘ì› ê°€ê¹Œì›€: 500~1000m
- ê³µì› ê°€ê¹Œì›€: 300~600m
- ëŒ€í˜•ë§ˆíŠ¸ ê°€ê¹Œì›€: 700~1200m
"""


class LLMParser:

    def __init__(self):
        print("ğŸ“Œ GPT-4.1 ê¸°ë°˜ LLM Parser Loaded")


    def parse_to_conditions(self, text: str) -> dict:
        """ ìì—°ì–´ â†’ GPT-4.1 JSON ë³€í™˜ """

        # API KEY ì—†ìœ¼ë©´ ë°”ë¡œ ì¤‘ë‹¨
        if client is None:
            return {"error": "OPENAI_API_KEY ì—†ìŒ. GPT íŒŒì„œ ë¹„í™œì„±í™”ë¨."}

        prompt = f"""
        ë„ˆëŠ” 'ì•„íŒŒíŠ¸ ì…ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ'ì˜ í•µì‹¬ íŒŒì„œì´ë‹¤.
        ì•„ë˜ ê¸°ì¤€(RAG ê¸°ì¤€ í¬í•¨)ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ë¬¸ì¥ì„ JSON ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•˜ë¼.

        {RAG_DISTANCE_HINT}

        ê·œì¹™:
        1) ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜
        2) keyëŠ” 'category_distance' í˜•íƒœ
        3) valueëŠ” int(meter)
        4) ê±°ë¦¬ í‘œí˜„ì„ ìˆ«ìë¡œ ë³€í™˜:
            ë§¤ìš° ê°€ê¹Œì›€ = 300m
            ê°€ê¹Œì›€ = 500m
            ë³´í†µ ê°€ê¹Œì›€ = 700m
            ë©€ì§€ ì•Šë‹¤ = 900m
        5) ì‹œì„¤ ì´ë¦„ ë§¤í•‘:
            ì§€í•˜ì² /ì „ì²  â†’ subway
            í•™êµ (ì´ˆë“±/ì¤‘ë“± ë¶ˆëª…) â†’ school
            ë³‘ì› â†’ hospital
            ê³µì› â†’ park
            ëŒ€í˜•ë§ˆíŠ¸ â†’ mart
            ë²„ìŠ¤ì •ë¥˜ì¥ â†’ bus

        ì…ë ¥ ë¬¸ì¥:
        "{text}"
        """

        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë¶€ë™ì‚° ê±°ë¦¬ ê¸°ì¤€ JSON ë³€í™˜ ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
        )

        raw = response.choices[0].message.content.strip()

        try:
            return json.loads(raw)
        except:
            return {
                "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                "raw_output": raw
            }
