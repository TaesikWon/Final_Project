# backend/llm_parser.py

from dotenv import load_dotenv
load_dotenv()

import os
import json
from openai import OpenAI

from backend.rag.rag_service import RAGService



# -----------------------------------------
# OpenAI API Key Load
# -----------------------------------------
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    print("âŒ ERROR: OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    client = None
else:
    client = OpenAI(api_key=api_key)


# -----------------------------------------
# LLM Parser Class
# -----------------------------------------
class LLMParser:

    def __init__(self):
        print("ğŸ“Œ RAG ê¸°ë°˜ GPT Parser Loaded")
        self.rag = RAGService()

    def parse_to_conditions(self, text: str) -> dict:
        """ ìì—°ì–´ â†’ JSON ë³€í™˜ (RAG ê¸°ë°˜) """

        if client is None:
            return {"error": "OPENAI_API_KEY ì—†ìŒ. GPT íŒŒì„œ ë¹„í™œì„±í™”ë¨."}

        # 1) RAG ê·œì¹™ ê²€ìƒ‰
        rag_rules = self.rag.search(text)
        rag_prompt = "\n".join([f"- {rule}" for rule in rag_rules])

        # 2) í”„ë¡¬í”„íŠ¸ ìƒì„± (f-string ì œê±°!)
        prompt = """
ë„ˆëŠ” 'ì•„íŒŒíŠ¸ ì…ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ'ì˜ ì¡°ê±´(JSON) ìƒì„± íŒŒì„œì´ë‹¤.

ì•„ë˜ëŠ” ì‚¬ìš©ì ìš”êµ¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ê±°ë¦¬ ê·œì¹™(RAG ê²€ìƒ‰ ê²°ê³¼)ì´ë‹¤:
%s

ìœ„ ê·œì¹™ì„ ì°¸ê³ í•˜ì—¬ ì…ë ¥ ë¬¸ì¥ì„ JSON ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•˜ë¼.

ê·œì¹™:
1) ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)
2) keyëŠ” '{category}_distance' í˜•íƒœ
3) valueëŠ” meter ë‹¨ìœ„ ì •ìˆ˜
4) ì‹œì„¤ëª… ë§¤í•‘:
    - ì§€í•˜ì² /ì „ì² /ì—­ â†’ subway
    - í•™êµ/ì´ˆì¤‘ë“± ë¶ˆëª… â†’ school
    - ë³‘ì›/ì˜ì›/ì¹˜ê³¼ â†’ hospital
    - ê³µì› â†’ park
    - ë§ˆíŠ¸/ì´ë§ˆíŠ¸/ì‹œì¥ â†’ mart
    - ë²„ìŠ¤/ì •ë¥˜ì¥ â†’ bus

ì…ë ¥ ë¬¸ì¥:
\"%s\"
""" % (rag_prompt, text)

        # 3) OpenAI í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” JSON ìƒì„± ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
        )

        raw = response.choices[0].message.content.strip()

        # 4) JSON ë³€í™˜
        try:
            return json.loads(raw)
        except:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw_output": raw}
